{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/islandz/Documents/Horse/HRNet/deep-high-resolution-net.pytorch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pprint\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from yacs.config import CfgNode as CN\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from tools import _init_paths\n",
    "from lib.config import cfg\n",
    "from lib.config import update_config\n",
    "from lib.core.loss import JointsMSELoss\n",
    "from lib.core.function import train\n",
    "from lib.core.function import validate\n",
    "from lib.utils.utils import get_optimizer\n",
    "from lib.utils.utils import save_checkpoint\n",
    "from lib.utils.utils import create_logger\n",
    "from lib.utils.utils import get_model_summary\n",
    "\n",
    "from lib.dataset.coco import COCODataset\n",
    "from lib.models.pose_hrnet import get_pose_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = pd.read_csv(\"horse.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = list(csv_data[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/islandz/Documents/Horse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=> num_images: 142\n",
      "=> num_images: 142\n",
      "=> num_images: 142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset = COCODataset(cfg, root, img_list, is_train=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGE2 = CN()\n",
    "STAGE2.NUM_MODULES = 1\n",
    "STAGE2.NUM_BRANCHES = 2\n",
    "STAGE2.NUM_BLOCKS = [4, 4]\n",
    "STAGE2.NUM_CHANNELS = [32, 64]\n",
    "STAGE2.BLOCK = 'BASIC'\n",
    "STAGE2.FUSE_METHOD = 'SUM'\n",
    "\n",
    "STAGE3 = CN()\n",
    "STAGE3.NUM_MODULES = 1\n",
    "STAGE3.NUM_BRANCHES = 3\n",
    "STAGE3.NUM_BLOCKS = [4, 4, 4]\n",
    "STAGE3.NUM_CHANNELS = [32, 64, 128]\n",
    "STAGE3.BLOCK = 'BASIC'\n",
    "STAGE3.FUSE_METHOD = 'SUM'\n",
    "\n",
    "STAGE4 = CN()\n",
    "STAGE4.NUM_MODULES = 1\n",
    "STAGE4.NUM_BRANCHES = 4\n",
    "STAGE4.NUM_BLOCKS = [4, 4, 4, 4]\n",
    "STAGE4.NUM_CHANNELS = [32, 64, 128, 256]\n",
    "STAGE4.BLOCK = 'BASIC'\n",
    "STAGE4.FUSE_METHOD = 'SUM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_pose_net(cfg, STAGE2, STAGE3, STAGE4, is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='Train keypoints network')\n",
    "    # general\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        required=True,\n",
    "                        type=str)\n",
    "\n",
    "    parser.add_argument('opts',\n",
    "                        help=\"Modify config options using the command-line\",\n",
    "                        default=None,\n",
    "                        nargs=argparse.REMAINDER)\n",
    "\n",
    "    # philly\n",
    "    parser.add_argument('--modelDir',\n",
    "                        help='model directory',\n",
    "                        type=str,\n",
    "                        default='')\n",
    "    parser.add_argument('--logDir',\n",
    "                        help='log directory',\n",
    "                        type=str,\n",
    "                        default='')\n",
    "    parser.add_argument('--dataDir',\n",
    "                        help='data directory',\n",
    "                        type=str,\n",
    "                        default='')\n",
    "    parser.add_argument('--prevModelDir',\n",
    "                        help='prev Model directory',\n",
    "                        type=str,\n",
    "                        default='')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating coco/pose_hrnet/Output\n",
      "=> creating coco/pose_hrnet/Output_2022-11-18-17-21\n"
     ]
    }
   ],
   "source": [
    "logger, final_output_dir, tb_log_dir = create_logger(\n",
    "    cfg, \"Output\", 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudnn related setting\n",
    "cudnn.benchmark = cfg.CUDNN.BENCHMARK\n",
    "torch.backends.cudnn.deterministic = cfg.CUDNN.DETERMINISTIC\n",
    "torch.backends.cudnn.enabled = cfg.CUDNN.ENABLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Parameters: 9,301,910\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Total Multiply Adds (For Convolution and Linear Layers only): 4.316820859909058 GFLOPs\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of Layers\n",
      "Conv2d : 104 layers   BatchNorm2d : 103 layers   ReLU : 97 layers   Bottleneck : 4 layers   BasicBlock : 36 layers   Upsample : 7 layers   HighResolutionModule : 3 layers   \n",
      "\n",
      "Total Parameters: 9,301,910\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Total Multiply Adds (For Convolution and Linear Layers only): 4.316820859909058 GFLOPs\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of Layers\n",
      "Conv2d : 104 layers   BatchNorm2d : 103 layers   ReLU : 97 layers   Bottleneck : 4 layers   BasicBlock : 36 layers   Upsample : 7 layers   HighResolutionModule : 3 layers   \n",
      "\n",
      "Total Parameters: 9,301,910\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Total Multiply Adds (For Convolution and Linear Layers only): 4.316820859909058 GFLOPs\n",
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "Number of Layers\n",
      "Conv2d : 104 layers   BatchNorm2d : 103 layers   ReLU : 97 layers   Bottleneck : 4 layers   BasicBlock : 36 layers   Upsample : 7 layers   HighResolutionModule : 3 layers   \n"
     ]
    }
   ],
   "source": [
    "writer_dict = {\n",
    "    'writer': SummaryWriter(log_dir=tb_log_dir),\n",
    "    'train_global_steps': 0,\n",
    "    'valid_global_steps': 0,\n",
    "}\n",
    "\n",
    "dump_input = torch.rand(\n",
    "    (1, 3, cfg.MODEL.IMAGE_SIZE[1], cfg.MODEL.IMAGE_SIZE[0])\n",
    ")\n",
    "writer_dict['writer'].add_graph(model, (dump_input, ))\n",
    "\n",
    "logger.info(get_model_summary(model, dump_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [23], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Data loading code\u001b[39;00m\n\u001b[1;32m      9\u001b[0m normalize \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mNormalize(\n\u001b[1;32m     10\u001b[0m     mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 13\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSHUFFLE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWORKERS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIN_MEMORY\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:353\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 353\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "#model.cuda()\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "criterion = JointsMSELoss(\n",
    "    use_target_weight=cfg.LOSS.USE_TARGET_WEIGHT\n",
    ")#.cuda()\n",
    "\n",
    "# Data loading code\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=cfg.TRAIN.SHUFFLE,\n",
    "    num_workers=cfg.WORKERS,\n",
    "    pin_memory=cfg.PIN_MEMORY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_perf = 0.0\n",
    "best_model = False\n",
    "last_epoch = -1\n",
    "optimizer = get_optimizer(cfg, model)\n",
    "begin_epoch = cfg.TRAIN.BEGIN_EPOCH\n",
    "checkpoint_file = os.path.join(\n",
    "    final_output_dir, 'checkpoint.pth'\n",
    ")\n",
    "\n",
    "if cfg.AUTO_RESUME and os.path.exists(checkpoint_file):\n",
    "    logger.info(\"=> loading checkpoint '{}'\".format(checkpoint_file))\n",
    "    checkpoint = torch.load(checkpoint_file)\n",
    "    begin_epoch = checkpoint['epoch']\n",
    "    best_perf = checkpoint['perf']\n",
    "    last_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    logger.info(\"=> loaded checkpoint '{}' (epoch {})\".format(\n",
    "        checkpoint_file, checkpoint['epoch']))\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "    optimizer, cfg.TRAIN.LR_STEP, cfg.TRAIN.LR_FACTOR,\n",
    "    last_epoch=last_epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(begin_epoch, cfg.TRAIN.END_EPOCH):\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # train for one epoch\n",
    "    train(cfg, train_loader, model, criterion, optimizer, epoch,\n",
    "          final_output_dir, tb_log_dir)\n",
    "    \n",
    "    logger.info('=> saving checkpoint to {}'.format(final_output_dir))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'model': cfg.MODEL.NAME,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, best_model, final_output_dir)\n",
    "\n",
    "final_model_state_file = os.path.join(\n",
    "    final_output_dir, 'final_state.pth'\n",
    ")\n",
    "logger.info('=> saving final model state to {}'.format(\n",
    "    final_model_state_file)\n",
    ")\n",
    "torch.save(model.module.state_dict(), final_model_state_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
